{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1oqUpuXMZnY8FUOuSCQED7sVUchgCv-OT","timestamp":1755031497578}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q6T8wh75oXQY","executionInfo":{"status":"ok","timestamp":1755720525207,"user_tz":300,"elapsed":32648,"user":{"displayName":"Catherine Wimmer","userId":"04746326930963302714"}},"outputId":"11cdf1d4-526b-475b-d354-a303de4e6c36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"/content/drive/MyDrive/GenAI final project/cleaned_product_data.csv\")"],"metadata":{"id":"we5qHxAUowq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1755754991938,"user_tz":300,"elapsed":153,"user":{"displayName":"Sara Chaker","userId":"18245270887197727620"}},"outputId":"03c30314-cd03-499d-de9e-c780561b3cca","id":"g1CMpfLzL8E5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               Image  \\\n","0  https://images-na.ssl-images-amazon.com/images...   \n","1  https://images-na.ssl-images-amazon.com/images...   \n","2  https://images-na.ssl-images-amazon.com/images...   \n","3  https://images-na.ssl-images-amazon.com/images...   \n","4  https://images-na.ssl-images-amazon.com/images...   \n","\n","                                    full_description  \n","0  Title: DB Longboards CoreFlex Crossbow 41\" Bam...  \n","1  Title: Electronic Snap Circuits Mini Kits Clas...  \n","2  Title: 3Doodler Create Flexy 3D Printing Filam...  \n","3  Title: Guillow Airplane Design Studio with Tra...  \n","4  Title: Woodstock- Collage 500 pc Puzzle\\nBrand...  "],"text/html":["\n","  <div id=\"df-17a175e7-91d1-4abd-907f-e7a845bdf9e8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image</th>\n","      <th>full_description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://images-na.ssl-images-amazon.com/images...</td>\n","      <td>Title: DB Longboards CoreFlex Crossbow 41\" Bam...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://images-na.ssl-images-amazon.com/images...</td>\n","      <td>Title: Electronic Snap Circuits Mini Kits Clas...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://images-na.ssl-images-amazon.com/images...</td>\n","      <td>Title: 3Doodler Create Flexy 3D Printing Filam...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://images-na.ssl-images-amazon.com/images...</td>\n","      <td>Title: Guillow Airplane Design Studio with Tra...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://images-na.ssl-images-amazon.com/images...</td>\n","      <td>Title: Woodstock- Collage 500 pc Puzzle\\nBrand...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17a175e7-91d1-4abd-907f-e7a845bdf9e8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-17a175e7-91d1-4abd-907f-e7a845bdf9e8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-17a175e7-91d1-4abd-907f-e7a845bdf9e8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-b9b373a8-75ce-4ef1-84cf-bdd46cf05442\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9b373a8-75ce-4ef1-84cf-bdd46cf05442')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-b9b373a8-75ce-4ef1-84cf-bdd46cf05442 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 10001,\n  \"fields\": [\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9924,\n        \"samples\": [\n          \"https://images-na.ssl-images-amazon.com/images/I/41i7duScngL.jpg\",\n          \"https://images-na.ssl-images-amazon.com/images/I/31cwD%2B6mDjL.jpg\",\n          \"https://images-na.ssl-images-amazon.com/images/I/31xbGDp4CQL.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9993,\n        \"samples\": [\n          \"Title: Rubie's Costume Co. Baby Turtle Costume\\nBrand: None\\nPrice: $28.01 - $33.22\\nCategory: Clothing, Shoes & Jewelry | Costumes & Accessories | Kids & Baby | Baby | Baby Boys\\nAbout: 100% Polyester | Imported | Hand Wash | Romper with attached padded shell and headpiece | Romper does not have sleeves or legs | Costumes are not sized the same as clothing, important to consult Rubie's baby size chart before selecting | Adorable choice for baby pictures | Rubie's costume company, family-owned and family-run from new York since 1950\\nDescription: None\\nSpecs: None\\nTechnical: show up to 2 reviews by default Rubie's costume company has the licensed and non-licensed costumes, decor, and accessories for every season: Halloween, Christmas, mardi gras, Easter, and all in-between. A leading innovator in the industry, in business and stocking product 12 months a year, Rubie's has the broadest product line of any costume company. Rubie's has more than 2 million square feet of office, development, warehouse, and production space. Products are manufactured all over the world, with approximately 35 percent of annual sales produced in Rubie's owned us factories. Family-owned and operated in new York state since 1950, Rubie's has a serious mission to make dress-up fun and safe. You'll find traditional costumes for kids and adults, flirty looks for women, mascot and rental quality costumes, haunted house decor, masks, wigs, accessories, shoes, and more - you'll find it all under the Rubie's brand\",\n          \"Title: The Puppet Company Large Birds Love Bird Hand Puppet\\nBrand: None\\nPrice: $21.97\\nCategory: Toys & Games | Puppets & Puppet Theaters | Hand Puppets\\nAbout: Make sure this fits by entering your model number. | This glove puppet from The Puppet Company has a wonderful face, long pile and beautifully printed finishes along with a squawk and full working mouth! | Fantastic play value and great for instigating \\\"Tidy Up Time\\\". | Designed to fit children and adult hands. | Access in base of puppet. | Suitable for children aged 18 months and above. Average Height 29\\\" excluding tail.\\nDescription: None\\nSpecs: ProductDimensions:11x11.5x29inches|ItemWeight:9.6ounces|ShippingWeight:9.6ounces(Viewshippingratesandpolicies)|DomesticShipping:ItemcanbeshippedwithinU.S.|InternationalShipping:ThisitemcanbeshippedtoselectcountriesoutsideoftheU.S.LearnMore|ASIN:B00AYGMWR4|Itemmodelnumber:PC003112|Manufacturerrecommendedage:18months-15years\\nTechnical: Go to your orders and start the return Select the ship method Ship it! | Go to your orders and start the return Select the ship method Ship it! | show up to 2 reviews by default This glove puppet from The Puppet Company has a wonderful face, long pile and beautifully printed finishes along with a squawk and full working mouth! One of over 400 beautiful puppets designed by The Puppet Company. Other products in our collection include Finger Puppets, Hand Puppets, Marionettes and Puppet Theatres! | 9.6 ounces (View shipping rates and policies)\",\n          \"Title: Waypoint Geographic Magneglobe Date World Globe with Stand-Includes 32 Magnetic Pins for Marking Travels and Fun Points of Interest (Classic Ocean)\\nBrand: None\\nPrice: $59.99\\nCategory: Toys & Games | Learning & Education | Geographic Globes\\nAbout: Make sure this fits by entering your model number. | For your past & future travels: our magnetic world Globe will hopefully allow you to reminisce about the places you have travelled and help you Plan out your future adventures by pinpointing different locations with the magnetic pins provided. It features an educational and up-to-date world map with more than 100 geographic points of reference, boarders, countries and Topographical features. | GO ON A JOURNEY AROUND THE WORLD: Spin the Waypoint Geographic Magneglobe to the left or to the right and gain full view and access to all the magnetic pins you have placed over the years! It comes with a stainless steel inclined stand and it makes for the perfect decoration for your home or office desk. | 32 magnetic pins included: our world Globe comes with 32 magnetic pins of various colors that you can use to eventually fill out the Globe with your past, current and future travel destinations. Mark the places you have seen, the places you are planning to visit soon and the places you wish you could visit in the future! | THE MOST THROUGHTFUL GIFT IDEA: If you have a friend who\\u2019s a keen traveler or adventurer or somebody who simply enjoys geographic content and brushing up on his geography skills, get them this magnetic globe and it will definitely be appreciated. In fact, they will be thinking of you every time they stick a magnetic pin on the globe! | LOVE IT OR YOUR MONEY BACK: Coming in at 11.5\\\" H x 9\\\" W x 9\\\" D, Magneglobe is great for adults, teenagers as well as toddlers as it is the ultimate educational and learning tool. Make it yours today and if you are not 110% thrilled with your purchase, rest assured it is covered under the umbrella of our 1-Year, Money Back Guarantee!\\nDescription: None\\nSpecs: ProductDimensions:9x9x11.5inches|ItemWeight:3pounds|ShippingWeight:3.8pounds(Viewshippingratesandpolicies)|DomesticShipping:ItemcanbeshippedwithinU.S.|InternationalShipping:ThisitemcanbeshippedtoselectcountriesoutsideoftheU.S.LearnMore|ASIN:B075S98JZB|Itemmodelnumber:WP50100|Manufacturerrecommendedage:3yearsandup\\nTechnical: Color:Classic Antique show up to 2 reviews by default Discover How You Can Brush Up On Your Geography Skills While Thinking About The Places You\\u2019ve Visited & The Places You Plan On Visiting! Are you looking for an authentic magnet globe that will allow you to mark all the places that are of interest to you? Or perhaps you\\u2019re searching for a novelty decoration idea for you or your friend\\u2026 Either way, we\\u2019ve got just the item for you! Presenting Magneglobe: The Ultimate Magnetic World Globe With Magnetic Pins [Classic Oceans] Magneglobe is a much-valued item by travelers around the world. In fact, you can use it to pinpoint different locations whether you wish to learn more about them or it\\u2019s simply places you have visited over the years. Within the package you will find 32 magnetic pins of different colors which perfectly adhere to the surface of the globe without magnetizing each other. Place them over the countries, cities and mountains you\\u2019ve been to, the places you are going to visit soon and the places you wish you could visit in the future! Great Learning Tool For All Ages Our magnetic world globe is not just amazing for adults looking for a decorative item for their home or office desk\\u2026it\\u2019s also great for toddlers and teenagers as it contains a significant level of detail with more than 100 geographic points of reference, boarders, countries and unique topographical features! Please note that Magneglobe is NOT suitable for children less than 3 years of age as it does contain various small parts which could be a potential hazard. So What Are You Waiting For? Scroll Up, Click \\u2018Add To Cart\\u2019 And Make It Yours Today! | 3.8 pounds (View shipping rates and policies)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755754991941,"user_tz":300,"elapsed":4,"user":{"displayName":"Sara Chaker","userId":"18245270887197727620"}},"outputId":"13b2dc4a-a088-4e64-c9ff-0c71809d9978","id":"ItI013CdL-Hf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10001 entries, 0 to 10000\n","Data columns (total 2 columns):\n"," #   Column            Non-Null Count  Dtype \n","---  ------            --------------  ----- \n"," 0   Image             10001 non-null  object\n"," 1   full_description  10001 non-null  object\n","dtypes: object(2)\n","memory usage: 156.4+ KB\n"]}]},{"cell_type":"markdown","source":["## Finetune CLIP to improve Recall"],"metadata":{"id":"9MxzM_ZDlH2l"}},{"cell_type":"code","source":["!pip install -q open-clip-torch timm torchmetrics"],"metadata":{"id":"RKdPe8vglgIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch, torch.nn as nn, torch.nn.functional as F\n","import open_clip, random, numpy as np, pandas as pd, requests, re\n","from PIL import Image\n","from io import BytesIO\n","from torch.utils.data import Dataset, DataLoader\n","from torchmetrics.functional import retrieval_recall\n","from functools import lru_cache\n","\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model, _, preprocess = open_clip.create_model_and_transforms(\n","    'ViT-L-14-336', pretrained='openai', device=device)\n","\n","tokenizer = open_clip.get_tokenizer('ViT-L-14-336')\n","\n","\n","for p in model.parameters():\n","    p.requires_grad = False\n","\n","# Unfreeze the final transformer block of the image encoder block\n","for p in model.visual.transformer.resblocks[-1].parameters():\n","    p.requires_grad = True\n","\n","# Unfreeze the final transformer block of the text encoder block\n","for p in model.transformer.resblocks[-1].parameters():\n","    p.requires_grad = True\n","\n","# Unfreeze the `logit_scale` parameter.\n","model.logit_scale.requires_grad = True"],"metadata":{"id":"P6r-6yiglKEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Custom text cleaning/summarizing for CLIP\n","def count_clip_tokens(text: str) -> int:\n","    return len(tokenizer.encode(text)) + 2\n","\n","def clean_text(x: str) -> str:\n","    x = str(x or \"\")\n","    x = re.sub(r\"\\s+\", \" \", x)\n","    x = x.replace(\"|\", \", \")\n","    return x.strip()\n","\n","# Strip boilerplate / disclaimers / marketing fluff\n","_BOILER = [\n","    r\"make sure this fits.*?$\",\n","    r\"warning:.*?$\",\n","    r\"view shipping rates.*?$\",\n","    r\"not real food.*?$\",\n","    r\"for ages\\s*\\d+\\+?\",\n","    r\"choking hazard.*?$\",]\n","\n","_boiler_re = re.compile(\"|\".join(_BOILER), flags=re.I)\n","\n","def strip_boilerplate(s: str) -> str:\n","    return _boiler_re.sub(\"\", s)\n","\n","# Parse labeled sections like \"Title:\", \"Category:\", etc.\n","_SECTION_KEYS = [\"Title\",\"Brand\",\"Price\",\"Category\",\"About\",\"Description\",\"Specs\",\"Technical\"]\n","_SECTION_RE = re.compile(\n","    r\"(Title|Brand|Price|Category|About|Description|Specs|Technical)\\s*:\\s*(.*?)\\s*(?=(Title|Brand|Price|Category|About|Description|Specs|Technical)\\s*:|$)\",\n","    flags=re.I|re.DOTALL)\n","\n","def extract_sections(text: str) -> dict:\n","    text = clean_text(text)\n","    sec = {}\n","    for k, v, _ in _SECTION_RE.findall(text):\n","        sec[k.capitalize()] = clean_text(v)\n","    if not sec:\n","        sec[\"Description\"] = text\n","    return sec\n","\n","def split_phrases(s: str):\n","    # break on pipes, bullets, semicolons, or sentence ends\n","    parts = re.split(r\"[|•·;]+|\\s*(?<=\\.)\\s+|\\n+\", s)\n","    return [p.strip(\" ,.-\") for p in parts if p and len(p.strip()) > 2]\n","\n","def score_phrase(p: str) -> float:\n","    # prefer phrases with numbers and moderate length\n","    has_num = 1.5 if re.search(r\"\\d\", p) else 0.0\n","    length = min(len(p), 80) / 80.0\n","    return has_num + length\n","\n","def pick_phrases(phrases, max_n=15):\n","    # dedupe (case-insensitive) then rank\n","    seen = set(); uniq = []\n","    for p in phrases:\n","        q = p.lower()\n","        if q not in seen:\n","            seen.add(q); uniq.append(p)\n","    uniq.sort(key=score_phrase, reverse=True)\n","    return uniq[:max_n]\n","\n","def shorten_category(cat: str) -> str:\n","    if not cat: return \"\"\n","    parts = [c.strip() for c in re.split(r\"[|/>]\", cat) if c.strip()]\n","    return \", \".join(parts[:2])\n","\n","def compress_specs(specs: str) -> str:\n","    if not specs: return \"\"\n","    parts = [p.strip() for p in re.split(r\"[|,;/]\", specs)]\n","    parts = [p for p in parts if re.search(r\"\\d\", p)]  # keep numeric bits\n","    return \", \".join(parts[:6])\n","\n","def pack_for_clip(full_text: str) -> str:\n","    sec = extract_sections(full_text)\n","    title = sec.get(\"Title\",\"\")\n","    cat   = shorten_category(sec.get(\"Category\",\"\"))\n","    about = \" \".join([sec.get(\"About\",\"\"), sec.get(\"Description\",\"\"), sec.get(\"Technical\",\"\")])\n","    about = strip_boilerplate(about)\n","    phrases = pick_phrases(split_phrases(about), max_n=18)\n","    specs = compress_specs(sec.get(\"Specs\",\"\"))\n","\n","    pieces = []\n","    if title: pieces.append(f\"Title: {title}\")\n","    if cat:   pieces.append(f\"Category: {cat}\")\n","\n","    # add phrases until we hit the token ceiling\n","    for ph in phrases:\n","        candidate = \" | \".join(pieces + [ph])\n","        if count_clip_tokens(candidate) <= 77:\n","            pieces.append(ph)\n","        else:\n","            break\n","\n","    if specs:\n","        candidate = \" | \".join(pieces + [f\"Specs: {specs}\"])\n","        if count_clip_tokens(candidate) <= 77:\n","            pieces.append(f\"Specs: {specs}\")\n","\n","    packed = \" | \".join(pieces)\n","\n","    # final tiny trim if needed\n","    while count_clip_tokens(packed) > 77 and \" \" in packed:\n","        packed = packed.rsplit(\" \", 1)[0]\n","    return packed"],"metadata":{"id":"9tzXTwnGYjk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["session = requests.Session()\n","session.headers.update({\"User-Agent\":\"Mozilla/5.0\"})\n","\n","# PyTorch Dataset for loading (image, text) pairs from a DataFrame\n","class ProductPairs(Dataset):\n","    def __init__(self, df):\n","        self.df = df.reset_index(drop=True)\n","\n","    @lru_cache(maxsize=4096)\n","    def _load_img(self, url):\n","        r = session.get(url, timeout=10); r.raise_for_status()\n","        return Image.open(BytesIO(r.content)).convert(\"RGB\")\n","\n","    def __len__(self): return len(self.df)\n","\n","    def __getitem__(self, i):\n","        row = self.df.iloc[i]\n","        img = self._load_img(row['Image'])\n","        text = pack_for_clip(row['full_description'])\n","        return preprocess(img), text\n","\n","# Collate function for PyTorch DataLoader\n","def collate_fn(batch):\n","    imgs, texts = zip(*batch)\n","    toks = tokenizer(list(texts))\n","    return torch.stack(imgs), toks"],"metadata":{"id":"pEhKoaQ4lvTo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build CLIP embeddings\n","_session = requests.Session()\n","_session.headers.update({\"User-Agent\": \"Mozilla/5.0 (open-clip)\"})\n","\n","def embed_text(text: str):\n","    s = (text or \"\")[:480]\n","    toks = tokenizer([s]).to(device)            # <-- open_clip tokenizer\n","    with torch.no_grad():\n","        vec = model.encode_text(toks)\n","        vec = F.normalize(vec, dim=-1)\n","    return vec.squeeze(0).detach().cpu().numpy().astype(\"float32\")\n","\n","def embed_image(url_or_pil):\n","    try:\n","        if isinstance(url_or_pil, str):\n","            r = _session.get(url_or_pil, timeout=12)\n","            r.raise_for_status()\n","            img = Image.open(BytesIO(r.content)).convert(\"RGB\")\n","        else:\n","            img = url_or_pil.convert(\"RGB\")\n","\n","        t = preprocess(img).unsqueeze(0).to(device)\n","        with torch.no_grad():\n","            vec = model.encode_image(t)\n","            vec = F.normalize(vec, dim=-1)\n","        return vec.squeeze(0).detach().cpu().numpy().astype(\"float32\")\n","    except Exception:\n","        return None\n","\n","# sanity check: should be 768 for ViT-L/14-336\n","with torch.no_grad():\n","    d_t = model.encode_text(tokenizer([\"test\"]).to(device)).shape[-1]\n","    print(\"Embed dim:\", d_t)"],"metadata":{"id":"aGgHzIbgDOul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","text_vecs, image_vecs, kept_idx, packed_texts = [], [], [], []\n","\n","for i, row in tqdm(df.iterrows(), total=len(df)):\n","    packed = pack_for_clip(row[\"full_description\"])\n","    tvec = embed_text(packed)                   # <-- uses open_clip\n","    ivec = embed_image(row[\"Image\"])            # <-- uses open_clip\n","    if ivec is None:\n","        continue\n","    text_vecs.append(tvec)\n","    image_vecs.append(ivec)\n","    packed_texts.append(packed)\n","    kept_idx.append(i)"],"metadata":{"id":"7_7ymErtaUZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Embedd\n","text_mat  = np.vstack(text_vecs).astype(\"float32\")\n","image_mat = np.vstack(image_vecs).astype(\"float32\")\n","meta = df.iloc[kept_idx].copy()\n","meta[\"clip_packed\"] = packed_texts\n","\n","text_mat.shape, image_mat.shape, meta.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755755646472,"user_tz":300,"elapsed":30,"user":{"displayName":"Sara Chaker","userId":"18245270887197727620"}},"outputId":"e6f532e5-87a4-429b-c52c-72ab8b49aae9","id":"DMQZj2QSLhGK"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((9974, 768), (9974, 768), (9974, 3))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Split train/val (e.g., 90/10)\n","df_train = meta[['Image','full_description']].sample(frac=0.90, random_state=42)\n","df_val   = meta.drop(df_train.index)\n","\n","train_ds = ProductPairs(df_train)\n","val_ds   = ProductPairs(df_val)\n","\n","BATCH = 64\n","train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=4, collate_fn=collate_fn, pin_memory=True)\n","val_dl   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=4, collate_fn=collate_fn, pin_memory=True)"],"metadata":{"id":"C79FqUz6ldeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clip_contrastive_loss(im_emb, tx_emb, logit_scale):\n","    # normalize\n","    im = F.normalize(im_emb, dim=-1)\n","    tx = F.normalize(tx_emb, dim=-1)\n","    logits_per_image  = logit_scale * im @ tx.t()\n","    logits_per_text   = logit_scale * tx @ im.t()\n","    targets = torch.arange(im.size(0), device=im.device)\n","    loss_i = F.cross_entropy(logits_per_image, targets)\n","    loss_t = F.cross_entropy(logits_per_text,  targets)\n","    return (loss_i + loss_t)/2\n","\n","# only train params with grad\n","opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n","                        lr=1e-5, weight_decay=0.2)\n","scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))"],"metadata":{"id":"FjG_wG8Plmhl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from time import time\n","\n","EPOCHS = 5\n","model.train()\n","for epoch in range(1, EPOCHS+1):\n","    t0 = time(); total = 0; n = 0\n","    for imgs, toks in train_dl:\n","        imgs = imgs.to(device, non_blocking=True)\n","        toks = toks.to(device, non_blocking=True)\n","\n","        opt.zero_grad(set_to_none=True)\n","        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n","            im_emb = model.encode_image(imgs)\n","            tx_emb = model.encode_text(toks)\n","            loss = clip_contrastive_loss(im_emb, tx_emb, model.logit_scale.exp())\n","        scaler.scale(loss).backward()\n","        scaler.step(opt); scaler.update()\n","\n","        total += loss.item()*imgs.size(0); n += imgs.size(0)\n","\n","    print(f\"Epoch {epoch} | train loss {total/n:.4f} | time {(time()-t0):.1f}s\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755756345651,"user_tz":300,"elapsed":603656,"user":{"displayName":"Sara Chaker","userId":"18245270887197727620"}},"outputId":"4b6ff091-1e1b-4b7b-d73b-062057644a99","id":"UHbFHkVJKtF8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4079732763.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 | train loss 0.1558 | time 56.2s\n","Epoch 2 | train loss 0.0992 | time 179.4s\n","Epoch 3 | train loss 0.0688 | time 196.8s\n","Epoch 4 | train loss 0.0474 | time 68.5s\n","Epoch 5 | train loss 0.0385 | time 102.7s\n"]}]},{"cell_type":"code","source":["model.eval()\n","\n","val_meta = df_val.reset_index(drop=True).copy()\n","\n","# IMAGES\n","img_vecs = []\n","with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n","    for i in range(0, len(val_meta), 64):\n","        batch = []\n","        for url in val_meta['Image'].iloc[i:i+64]:\n","            r = session.get(url, timeout=10); r.raise_for_status()\n","            im = Image.open(BytesIO(r.content)).convert(\"RGB\")\n","            batch.append(preprocess(im))\n","        batch = torch.stack(batch).to(device)\n","        v = model.encode_image(batch)\n","        v = F.normalize(v, dim=-1)\n","        img_vecs.append(v.cpu())\n","val_image_mat = torch.cat(img_vecs, dim=0).numpy().astype(\"float32\")\n","\n","# TEXTS\n","texts = [pack_for_clip(t) for t in val_meta['full_description'].tolist()]\n","text_vecs = []\n","with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n","    for i in range(0, len(texts), 256):\n","        toks = tokenizer(texts[i:i+256]).to(device)\n","        t = model.encode_text(toks)\n","        t = F.normalize(t, dim=-1)\n","        text_vecs.append(t.cpu())\n","val_text_mat = torch.cat(text_vecs, dim=0).numpy().astype(\"float32\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755756387497,"user_tz":300,"elapsed":32572,"user":{"displayName":"Sara Chaker","userId":"18245270887197727620"}},"outputId":"e16a5a03-8103-4af6-9c88-2899919563cd","id":"BuMi39PmKotM"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1038461157.py:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n","/tmp/ipython-input-1038461157.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"]}]},{"cell_type":"code","source":["!pip install faiss-cpu"],"metadata":{"id":"mfj-FcuPsUFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import faiss, numpy as np\n","\n","index = faiss.IndexFlatIP(val_image_mat.shape[1]); index.add(val_image_mat.astype(\"float32\"))\n","\n","def recall_at_k(text_mat, image_mat, K=1):\n","    idx = faiss.IndexFlatIP(image_mat.shape[1]); idx.add(image_mat)\n","    correct=0\n","    for i in range(text_mat.shape[0]):\n","        _, I = idx.search(text_mat[i:i+1], K)\n","        if i in I[0]: correct+=1\n","    return correct/len(text_mat)\n","\n","print(\"Recall@1:\", recall_at_k(val_text_mat, val_image_mat, 1))\n","print(\"Recall@5:\", recall_at_k(val_text_mat, val_image_mat, 5))\n","print(\"Recall@10:\", recall_at_k(val_text_mat, val_image_mat, 10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755756395755,"user_tz":300,"elapsed":449,"user":{"displayName":"Sara Chaker","userId":"18245270887197727620"}},"outputId":"8e618fd2-09f0-4f93-e105-4f0b45e626f7","id":"UQzRltp4KkA-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recall@1: 0.8064192577733199\n","Recall@5: 0.9628886659979939\n","Recall@10: 0.9869608826479438\n"]}]},{"cell_type":"code","source":["# export embeddings\n","import numpy as np, pandas as pd, hashlib, json, os\n","\n","N = text_mat.shape[0]\n","assert image_mat.shape[0] == N\n","\n","def stable_id(url):\n","    return hashlib.md5(url.encode('utf-8')).hexdigest()\n","\n","meta = meta.reset_index(drop=True).copy()\n","meta[\"id\"] = meta[\"Image\"].apply(stable_id)\n","\n","\n","payload = pd.DataFrame({\n","    \"id\": meta[\"id\"],\n","    \"image_url\": meta[\"Image\"],\n","    \"text_full\": meta[\"full_description\"],\n","    \"text_packed\": meta[\"clip_packed\"],})\n","\n","payload.head()"],"metadata":{"id":"oAOsXOvi8qx6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["faiss.write_index(index, \"clip_image.index\") # nearest-neighbor lookups locally without a separate vector database\n","meta.to_parquet(\"clip_meta.parquet\", index=False) # metadata"],"metadata":{"id":"9YleGlGj4b8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.save(\"clip_image_embeddings.npy\", image_mat) # embeddings for vector database"],"metadata":{"id":"946QzkEL51Ls"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save fine tune clip\n","torch.save(model.state_dict(), \"ft_clip.pt\")"],"metadata":{"id":"Ccg5bxAN6yRa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenizer + preprocess transforms\n","import pickle\n","with open(\"clip_preprocess.pkl\", \"wb\") as f:\n","    pickle.dump(preprocess, f)"],"metadata":{"id":"CfQ_Hb0q6z_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp ft_clip.pt \"/content/drive/MyDrive/GenAI final project\""],"metadata":{"id":"1kls_JzM7YEO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp clip_preprocess.pkl \"/content/drive/MyDrive/GenAI final project\""],"metadata":{"id":"heOxsc0U78zi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp clip_preprocess.pkl \"/content/drive/MyDrive/GenAI final project\""],"metadata":{"id":"yMDkymde8hyO"},"execution_count":null,"outputs":[]}]}